{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ast import arg\n",
    "from operator import neg\n",
    "import pandas as pd\n",
    "import posixpath,ntpath,json,platform,argparse\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def time_to_float(time):\n",
    "    \"\"\"\n",
    "        This function converts time to float.\n",
    "        time(str): string value to convert to float.\n",
    "    \"\"\"\n",
    "    time = str(time)\n",
    "    if time==\"nan\":\n",
    "        return 0\n",
    "    try:\n",
    "        (hours_, min_, sec_) = tuple(time.split(\":\"))\n",
    "        hour_ = int(hours_)\n",
    "        min_ = int(min_)\n",
    "        sec_ = int(sec_)\n",
    "        return hour_ * 3600 + min_ * 60 + sec_\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} occured for {time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Cusstomer Reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_customer_reaction(all_data):\n",
    "    \"\"\"\n",
    "        This function determines the customer's reaction, reactions are categoried into\n",
    "        positive(\"Love\",\"Care\"), negative(\"Sad\",\"Angry\") and neutral(\"Wow\",\"Haha\").\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"Love\",\"Care\",\"Sad\",\"Angry\",\"Wow\",\"Haha\"].\n",
    "    \"\"\"\n",
    "    positive = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"positive\"]])\n",
    "    negative = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"negative\"]])\n",
    "    neutral = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"neutral\"]])\n",
    "    pd_frame = pd.Series([positive,negative,neutral], index=[[\"positive\",\"negative\",\"neutral\"]])\n",
    "\n",
    "    reaction = pd_frame[pd_frame==pd_frame.max()].index[0][0]\n",
    "    data_map = [reaction]\n",
    "    return pd.Series(data_map, index=[\"customer_reaction\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Content Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_content_type(all_data):\n",
    "    \"\"\"\n",
    "        This function determines the content's type, contents  are categoried into\n",
    "        general_knowledge(messages that contains words related to entertainment and general information), \n",
    "        science_nd_religion(messages that contains words related to science and religion),\n",
    "        politics(messages that contains words related to politics) and\n",
    "        peace_nd_violence(messages that contains words related to peace and violence).\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"].\n",
    "    \"\"\"\n",
    "    general_knowledge = sum([int(all_data[each_pos]) for each_pos in content_type_[\"general_knowledge\"]])\n",
    "    science_nd_religion = sum([int(all_data[each_pos]) for each_pos in content_type_[\"science_nd_religion\"]])\n",
    "    politics = sum([int(all_data[each_pos]) for each_pos in content_type_[\"politics\"]])\n",
    "    peace_nd_violence = sum([int(all_data[each_pos]) for each_pos in content_type_[\"peace_nd_violence\"]])\n",
    "\n",
    "    pd_frame = pd.Series([general_knowledge,science_nd_religion,politics,peace_nd_violence], index=[[\"general_knowledge\",\"science_nd_religion\",\"politics\",\"peace_nd_violence\"]])\n",
    "    max_result = pd_frame[pd_frame==pd_frame.max()]\n",
    "    type_ = max_result.index[0][0]\n",
    "    # print(all_data[\"Message\"],pd_frame,pd_frame.max(),type_,max_result[type_])\n",
    "    data_map = [type_] if int(max_result[type_]) != 0 else [\"no_label\"]\n",
    "    return pd.Series(data_map, index=[\"content_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Date to Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_date_standard(input_date,format='%Y-%m-%d %H:%M:%S EDT'):\n",
    "    \"\"\"\n",
    "    This function converts time to float.\n",
    "    input_date(str): string value to convert to standard format.\n",
    "    format(str): string value used to format input_date.\n",
    "    \"\"\"\n",
    "    date_time_obj = None\n",
    "    try:\n",
    "        date_time_obj = datetime.strptime(input_date, format)\n",
    "    except:\n",
    "        try:\n",
    "            date_time_obj = datetime.strptime(input_date, '%Y-%m-%d%H:%M:%S EDT')\n",
    "        except:\n",
    "            try:\n",
    "                date_time_obj = datetime.strptime(input_date, '%Y-%m-%d %H:%M:%S EST')\n",
    "            except Exception as e:\n",
    "                print(f\"Error occured: {e} for {input_date}\")\n",
    "    return date_time_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Output File format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if output file is .csv\n",
    "def format_outfile_name(filename):\n",
    "    assert type(filename) == type(\" \"), \"format of filename should be string\"\n",
    "    return filename.split(\".\")[0]+\".csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert path from win to linux path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to handle user data path\n",
    "def convert_path_for_win_linux(path_):\n",
    "    if platform.machine() in (\"arm64\"):\n",
    "        path_ = path_.replace(ntpath.sep,posixpath.sep)\n",
    "    else:\n",
    "        path_ = path_.replace(posixpath.sep,ntpath.sep)\n",
    "    return path_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to open a json file\n",
    "def open_json_files(file_name):\n",
    "    assert \".json\" in file_name, \"File needs to be of type json\"\n",
    "    with open(file_name) as jsin_file:\n",
    "        jsin_file_loaded = json.load(jsin_file)\n",
    "    return jsin_file_loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if specific labels are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data\n",
    "def label_present(all_data):\n",
    "    \"\"\"\n",
    "        This function counts occurence of words to categories each message in one of the following\n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"],\n",
    "        words related to this categories can be found in `signal_categories.json.\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"].\n",
    "    \"\"\"\n",
    "    label_template_copy = label_template.copy()\n",
    "    data = all_data[\"Message\"]\n",
    "    data = str(data)\n",
    "    signal_categories_keys_ = list(label_template_copy.keys())\n",
    "    signal_categories_keys_.sort()\n",
    "\n",
    "    for each_cat in signal_categories_keys_:\n",
    "        for each_signal in labeller_[each_cat]:\n",
    "            if each_signal in data:\n",
    "                label_template_copy[each_cat] += 1\n",
    "                # print(f\"Key is {each_cat} and signal is {each_signal}\")\n",
    "    # if sum(label_template.values())==0:\n",
    "    #     label_template[\"general\"] = 1\n",
    "    # total_signals = sum([label_template[each_cat] for each_cat in signal_categories_keys_])\n",
    "    # data_map = [1 if (label_template[each_cat]/total_signals) > 0.1 else 0 for each_cat in signal_categories_keys_]\n",
    "    data_map = [label_template_copy[each_cat] for each_cat in signal_categories_keys_]\n",
    "    return pd.Series(data_map, index=signal_categories_keys_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run labellers and Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program Started Running ...\n",
      "File output saved in data/output/vice_data_with_signal_category.csv.\n",
      "Program Stopped Running.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Program Started Running ...\")\n",
    "# Read JSON signal_categories file\n",
    "labeller_ = open_json_files(\"process_json/signal_categories.json\")\n",
    "\n",
    "# Customer reaction data\n",
    "customer_reaction_ = open_json_files(\"process_json/customer_reaction.json\")\n",
    "content_type_ = open_json_files(\"process_json/content_type.json\")\n",
    "\n",
    "# Read JSON template file\n",
    "label_template = open_json_files(\"process_json/template.json\")\n",
    "\n",
    "important_columns = ['Post Created', 'Video Share Status', 'Total Views', \n",
    "                    'Total Views For All Crossposts', 'Video Length', \n",
    "                    'Message', 'Link Text', 'Likes at Posting','Likes',\n",
    "                    'Comments','Shares','Love','Wow','Haha','Sad', 'Angry', \n",
    "                    'Care']\n",
    "file_name = \"data/raw/vice_data_for_test_task.csv\"\n",
    "outputname = format_outfile_name(\"data/output/vice_data_with_signal_category.csv\")\n",
    "\n",
    "file_name = convert_path_for_win_linux(file_name)\n",
    "vice_data = pd.read_csv(file_name)[important_columns].reindex()\n",
    "vice_data['Post Created'] = vice_data[['Post Created']].applymap(convert_date_standard)\n",
    "vice_data['Video Length'] = vice_data[['Video Length']].applymap(time_to_float)\n",
    "vice_data2 = vice_data.apply(label_present,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data2], axis=1)\n",
    "vice_data3 = vice_data.apply(determine_customer_reaction,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data3], axis=1)\n",
    "vice_data4 = vice_data.apply(determine_content_type,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data4], axis=1).reindex()\n",
    "vice_data.to_csv(outputname,index=False)\n",
    "print(f\"File output saved in {outputname}.\\nProgram Stopped Running.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a href=\"https://datastudio.google.com/reporting/5f526187-6b3c-404c-87bc-97be2b3c7827/page/0bQoC/edit\">Visualisation - Click to view Additional dashboard link </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import new data\n",
    "new_data = pd.read_csv(\"data/output/vice_data_with_signal_category.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_Post_Content_Analysis](data/output/visualisations/All_Time_Post_Content_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_Post_Content_Category_Analysis](data/output/visualisations/All_Time_Post_Content_Category_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_Source_Analysis](data/output/visualisations/All_Time_Source_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_Total_Post_Analysis](data/output/visualisations/All_Time_Total_Post_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_User_Reaction_Analysis](data/output/visualisations/All_Time_User_Reaction_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_User_Reaction_Category_Analysis](data/output/visualisations/All_Time_User_Reaction_Category_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![All_Time_Video_Length_Analysis](data/output/visualisations/All_Time_Video_Length_Analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Content_Category_Overview](data/output/visualisations/Content_Category_Overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Content_Overview_By_User_Reaction](data/output/visualisations/Content_Overview_By_User_Reaction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Post_Source](data/output/visualisations/Post_Source.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![User_Reaction_By_Total_Posts](data/output/visualisations/User_Reaction_By_Total_Posts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![User_Reaction_Overview](data/output/visualisations/User_Reaction_Overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST SUBMISSION: DATA ANALYST <br>\n",
    "Below contains the details on findings from analysis done on the vice dataset. \n",
    "\n",
    "** Important metrics: **\n",
    "\n",
    "* Post Created – the timestamp denoting when the given post was made;\n",
    "\n",
    "* Video Share Status – owned (originally released by that page) vs crosspost (reposted from a different page);\n",
    "\n",
    "* Total Views – views the video amassed when it was published that one time;\n",
    "\n",
    "* Total Views For All Crossposts -  views the video has amassed over all times it was posted;\n",
    "\n",
    "* Video Length – duration of the video in minutes;\n",
    "\n",
    "* Message and Link Text – the description and title text viewers see next to the video;\n",
    "\n",
    "* Likes/Comments/Shares/Love/… - ways how viewers have engaged with the video.\n",
    "\n",
    "** Extra columns generated (these columns where generated to analyze content types using the message column, aim of this is to analyze the relationship between the categories of topics posted and the user interaction.): **\n",
    "\n",
    "* entertainment - counts all occurrence of words from post related to entertainment;\n",
    "\n",
    "* environment_&_economy - counts all occurence of words related to environment and economy post;\n",
    "\n",
    "* peace - counts all occurrence of words in post that has to do with non violence;\n",
    "\n",
    "* politics - counts all occurrence of words in post that has to do with politics;\n",
    "\n",
    "* religion - counts all occurence of words that has to do with religion and tradition;\n",
    "\n",
    "* science - counts all occurrence of words that has to do with science\n",
    "​\n",
    "* ​violence_&_crime - counts all occurrences of words that have to do with violence and crime.\n",
    "\n",
    "* customer_reaction - this categorize customer reactions into 3 classes (positive, negative and neural)\n",
    "\n",
    "* content_type - this classifies content sub-topics into 5 classes (no_label, general_knowledge, science_nd_religion, politics and peace_nd_violence) \n",
    "\n",
    "Code: <br>\n",
    "<a href=\"https://datastudio.google.com/reporting/5f526187-6b3c-404c-87bc-97be2b3c7827/page/0bQoC/edit\"> Code to process data and to generate new columns can be found here </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers(1) - Based on the data, comment on how VICE’s content strategy has shifted over time. You are free to focus on just a few aspects of your choice.\n",
    "\n",
    "* Based on the data, Overtime the vice strategy maintains a constant high post source from `cross posts` while the rest of the post is distributed between `Owned` and `Shared` posts.\n",
    "\n",
    "* The All time content analysis also revealed a constantly high post rate of `entertainment` related post from `May 2018` to `Oct 2018`, followed by an interwoven high post rate between `science` related post and `entertainment` related posts from `Oct 2018` to `Jan 2020`, After which a very high post rate of `science` related post was recorded in `March 2020` to `May 2020`, This same month and year a high post rate in `video length` from contents and a high `like reaction` from the user was recorded . In `Nov 2019` a very `high neural reaction` was recorded as `religion` related posts clocked its  highest all time post rate.\n",
    "\n",
    "* Finally on post source analysis, using the drill down feature available on the chart, we would find that 86% of vice total posts are from crosspost, 13% of vice total posts are owned, while the remaining 0.4% is shared. \n",
    "\n",
    "        - Drilling down one level into the chart for crosspost, we would find that crosspost has an almost balanced post rate between `general knowledge` posts and science posts at 24.6% for `science_nd_religion` and 24.2% for `general_knowledge`, for politics related posts we have a 12% rate and a 8.8% rate for violence_nd_peace related posts.\n",
    "\n",
    "        - Drilling down one level into the chart for owned, we would find that owned posts has a very high rate post on `general knowledge` at 38.6%, followed by a science posts at 16.1% for `science_nd_religion`, for politics related posts we have a 8% rate and a 5.6% rate for violence_nd_peace related posts.\n",
    "\n",
    "        - Drilling down one level into the chart for shared posts, we experience a bit in the post strategy, we would find that shared post has a high general_knowledge post at 26.3% and  a balanced post rate between `politics` posts and science_nd_religion posts at 8.8% for `politics` and 8.8% for `science_nd_religion`, finally we have a 3.7% rate for violence_nd_peace related posts.\n",
    "\n",
    "        - Across all posts sources we can conclude that vice post less `violence` and `crime` related posts and posts related to `general_knowledge`, `science` and `religion` are more promoted.\n",
    "\n",
    "Answers(2) - Are all kinds of engagement beneficial for video popularity? Naturally, a more popular video will have more reactions of all kinds, but does a higher fraction of, say, “Angry” reactions, have a negative effect on video performance?\n",
    "\n",
    "* From the all time trend analysis in the dashboard, we would notice an `opposite reaction` between `negative reactions` and `positive reactions`, videos with `high positive reactions` tend to have `low negative reactions` when compared to previous trends. So maybe individual user reactions might not directly have a clear effect on the performance, but with a further classification into clear `positive`, `negative` and `neutral` reactions, we can see that a grouped `negative reaction` can in turn affect a grouped `positive reaction`.\n",
    "\n",
    "Answers(3) - Are there any topics, word combinations which always perform higher than average, or have been successful as of recently? Hint: you could use NLP.\n",
    "\n",
    "* Given the high rate of `science` and `entertainment` related posts made, We would notice an all time direct positive effect of these topics on the positive reactions we get, we would also notice that as topics on violence and crime begin to tip to the top, positive reactions had a low performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Word combinations for each sub-topics generated for this analysis can be found here <br>\n",
    "* Sub-topic combination for post categories generated for this analysis can be found here <br>\n",
    "* User reaction combination to get reaction category for this analysis can be found here <br>\n",
    "* Final processed data used for this analysis can be found here <br>\n",
    "* Main script used to process data can be found here or this <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e2cbf7e24be81b209a41970079817caee206a1f251f9087bb988655c9697e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
