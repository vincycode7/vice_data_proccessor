{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ast import arg\n",
    "from operator import neg\n",
    "import pandas as pd\n",
    "import posixpath,ntpath,json,platform,argparse\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def time_to_float(time):\n",
    "    \"\"\"\n",
    "        This function converts time to float.\n",
    "        time(str): string value to convert to float.\n",
    "    \"\"\"\n",
    "    time = str(time)\n",
    "    if time==\"nan\":\n",
    "        return 0\n",
    "    try:\n",
    "        (hours_, min_, sec_) = tuple(time.split(\":\"))\n",
    "        hour_ = int(hours_)\n",
    "        min_ = int(min_)\n",
    "        sec_ = int(sec_)\n",
    "        return hour_ * 3600 + min_ * 60 + sec_\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} occured for {time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Cusstomer Reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_customer_reaction(all_data):\n",
    "    \"\"\"\n",
    "        This function determines the customer's reaction, reactions are categoried into\n",
    "        positive(\"Love\",\"Care\"), negative(\"Sad\",\"Angry\") and neutral(\"Wow\",\"Haha\").\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"Love\",\"Care\",\"Sad\",\"Angry\",\"Wow\",\"Haha\"].\n",
    "    \"\"\"\n",
    "    positive = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"positive\"]])\n",
    "    negative = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"negative\"]])\n",
    "    neutral = sum([int(all_data[each_pos]) for each_pos in customer_reaction_[\"neutral\"]])\n",
    "    pd_frame = pd.Series([positive,negative,neutral], index=[[\"positive\",\"negative\",\"neutral\"]])\n",
    "\n",
    "    reaction = pd_frame[pd_frame==pd_frame.max()].index[0][0]\n",
    "    data_map = [reaction]\n",
    "    return pd.Series(data_map, index=[\"customer_reaction\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Content Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def determine_content_type(all_data):\n",
    "    \"\"\"\n",
    "        This function determines the content's type, contents  are categoried into\n",
    "        general_knowledge(messages that contains words related to entertainment and general information), \n",
    "        science_nd_religion(messages that contains words related to science and religion),\n",
    "        politics(messages that contains words related to politics) and\n",
    "        peace_nd_violence(messages that contains words related to peace and violence).\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"].\n",
    "    \"\"\"\n",
    "    general_knowledge = sum([int(all_data[each_pos]) for each_pos in content_type_[\"general_knowledge\"]])\n",
    "    science_nd_religion = sum([int(all_data[each_pos]) for each_pos in content_type_[\"science_nd_religion\"]])\n",
    "    politics = sum([int(all_data[each_pos]) for each_pos in content_type_[\"politics\"]])\n",
    "    peace_nd_violence = sum([int(all_data[each_pos]) for each_pos in content_type_[\"peace_nd_violence\"]])\n",
    "\n",
    "    pd_frame = pd.Series([general_knowledge,science_nd_religion,politics,peace_nd_violence], index=[[\"general_knowledge\",\"science_nd_religion\",\"politics\",\"peace_nd_violence\"]])\n",
    "    max_result = pd_frame[pd_frame==pd_frame.max()]\n",
    "    type_ = max_result.index[0][0]\n",
    "    # print(all_data[\"Message\"],pd_frame,pd_frame.max(),type_,max_result[type_])\n",
    "    data_map = [type_] if int(max_result[type_]) != 0 else [\"no_label\"]\n",
    "    return pd.Series(data_map, index=[\"content_type\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Date to Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_date_standard(input_date,format='%Y-%m-%d %H:%M:%S EDT'):\n",
    "    \"\"\"\n",
    "    This function converts time to float.\n",
    "    input_date(str): string value to convert to standard format.\n",
    "    format(str): string value used to format input_date.\n",
    "    \"\"\"\n",
    "    date_time_obj = None\n",
    "    try:\n",
    "        date_time_obj = datetime.strptime(input_date, format)\n",
    "    except:\n",
    "        try:\n",
    "            date_time_obj = datetime.strptime(input_date, '%Y-%m-%d%H:%M:%S EDT')\n",
    "        except:\n",
    "            try:\n",
    "                date_time_obj = datetime.strptime(input_date, '%Y-%m-%d %H:%M:%S EST')\n",
    "            except Exception as e:\n",
    "                print(f\"Error occured: {e} for {input_date}\")\n",
    "    return date_time_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Output File format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if output file is .csv\n",
    "def format_outfile_name(filename):\n",
    "    assert type(filename) == type(\" \"), \"format of filename should be string\"\n",
    "    return filename.split(\".\")[0]+\".csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert path from win to linux path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to handle user data path\n",
    "def convert_path_for_win_linux(path_):\n",
    "    if platform.machine() in (\"arm64\"):\n",
    "        path_ = path_.replace(ntpath.sep,posixpath.sep)\n",
    "    else:\n",
    "        path_ = path_.replace(posixpath.sep,ntpath.sep)\n",
    "    return path_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to open a json file\n",
    "def open_json_files(file_name):\n",
    "    assert \".json\" in file_name, \"File needs to be of type json\"\n",
    "    with open(file_name) as jsin_file:\n",
    "        jsin_file_loaded = json.load(jsin_file)\n",
    "    return jsin_file_loaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if specific labels are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data\n",
    "def label_present(all_data):\n",
    "    \"\"\"\n",
    "        This function counts occurence of words to categories each message in one of the following\n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"],\n",
    "        words related to this categories can be found in `signal_categories.json.\n",
    "        all_data(dataframe): a pandas dataframe that at least the following columns \n",
    "        [\"entertainment\",\"science\",\"religion\",\"politics\",\"environment_&_economy\",\"peace\",\"violence_&_crime\"].\n",
    "    \"\"\"\n",
    "    label_template_copy = label_template.copy()\n",
    "    data = all_data[\"Message\"]\n",
    "    data = str(data)\n",
    "    signal_categories_keys_ = list(label_template_copy.keys())\n",
    "    signal_categories_keys_.sort()\n",
    "\n",
    "    for each_cat in signal_categories_keys_:\n",
    "        for each_signal in labeller_[each_cat]:\n",
    "            if each_signal in data:\n",
    "                label_template_copy[each_cat] += 1\n",
    "                # print(f\"Key is {each_cat} and signal is {each_signal}\")\n",
    "    # if sum(label_template.values())==0:\n",
    "    #     label_template[\"general\"] = 1\n",
    "    # total_signals = sum([label_template[each_cat] for each_cat in signal_categories_keys_])\n",
    "    # data_map = [1 if (label_template[each_cat]/total_signals) > 0.1 else 0 for each_cat in signal_categories_keys_]\n",
    "    data_map = [label_template_copy[each_cat] for each_cat in signal_categories_keys_]\n",
    "    return pd.Series(data_map, index=signal_categories_keys_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run labellers and Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program Started Running ...\n",
      "File output saved in data/output/vice_data_with_signal_category.csv.\n",
      "Program Stopped Running.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Program Started Running ...\")\n",
    "# Read JSON signal_categories file\n",
    "labeller_ = open_json_files(\"process_json/signal_categories.json\")\n",
    "\n",
    "# Customer reaction data\n",
    "customer_reaction_ = open_json_files(\"process_json/customer_reaction.json\")\n",
    "content_type_ = open_json_files(\"process_json/content_type.json\")\n",
    "\n",
    "# Read JSON template file\n",
    "label_template = open_json_files(\"process_json/template.json\")\n",
    "\n",
    "important_columns = ['Post Created', 'Video Share Status', 'Total Views', \n",
    "                    'Total Views For All Crossposts', 'Video Length', \n",
    "                    'Message', 'Link Text', 'Likes at Posting','Likes',\n",
    "                    'Comments','Shares','Love','Wow','Haha','Sad', 'Angry', \n",
    "                    'Care']\n",
    "file_name = \"data/raw/vice_data_for_test_task.csv\"\n",
    "outputname = format_outfile_name(\"data/output/vice_data_with_signal_category.csv\")\n",
    "\n",
    "file_name = convert_path_for_win_linux(file_name)\n",
    "vice_data = pd.read_csv(file_name)[important_columns].reindex()\n",
    "vice_data['Post Created'] = vice_data[['Post Created']].applymap(convert_date_standard)\n",
    "vice_data['Video Length'] = vice_data[['Video Length']].applymap(time_to_float)\n",
    "vice_data2 = vice_data.apply(label_present,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data2], axis=1)\n",
    "vice_data3 = vice_data.apply(determine_customer_reaction,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data3], axis=1)\n",
    "vice_data4 = vice_data.apply(determine_content_type,axis=1).reindex()\n",
    "vice_data = pd.concat([vice_data, vice_data4], axis=1).reindex()\n",
    "vice_data.to_csv(outputname,index=False)\n",
    "print(f\"File output saved in {outputname}.\\nProgram Stopped Running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e2cbf7e24be81b209a41970079817caee206a1f251f9087bb988655c9697e2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
